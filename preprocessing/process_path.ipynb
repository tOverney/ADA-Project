{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'agency_id', \n",
    "    'service_date_id', 'service_date_date',\n",
    "    'route_id', 'route_short_name', 'route_long_name',\n",
    "    'trip_id', 'trip_headsign', 'trip_short_name',\n",
    "    'stop_time_id', 'stop_time_arrival_time', 'stop_time_departure_time', 'stop_time_stop_sequence', \n",
    "    'stop_id', 'stop_stop_id', 'stop_name', \n",
    "    'capacity_path_id', 'capacity_path_path', \n",
    "    'capacity_capacity_id', 'capacity_capacity_capacity1st', 'capacity_capacity_capacity2nd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = \"in_data/\"\n",
    "out_dir = \"out_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = 6373.0\n",
    "def compute_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return (R * c)*1000\n",
    "\n",
    "max_depth = 10\n",
    "def bfs(graph, start, end, max_depth=max_depth):\n",
    "    queue = []\n",
    "    queue.append([start])\n",
    "    while queue:\n",
    "        path = queue.pop(0)\n",
    "        if len(path) > max_depth:\n",
    "            return []\n",
    "        \n",
    "        node = path[-1]\n",
    "        \n",
    "        if node == end:\n",
    "            return path\n",
    "\n",
    "        for adjacent in graph.get(node, []):\n",
    "            new_path = list(path)\n",
    "            new_path.append(adjacent)\n",
    "            queue.append(new_path)\n",
    "            \n",
    "    return [-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary edge_id to feature based on geojson\n",
    "with open(in_dir + 'edges.geojson') as file:\n",
    "    edgeid2feature = {}\n",
    "    data1 = json.load(file)\n",
    "    for feature in data1['features']:\n",
    "        edgeid2feature[feature['properties']['edge_id']] = feature\n",
    "\n",
    "# Dictionary stop_id to feature    \n",
    "with open(in_dir + 'stations.geojson') as file:\n",
    "    stopid2coord = {}\n",
    "    data2 = json.load(file)\n",
    "    for feature in data2['features']:\n",
    "        stopid2coord[feature['properties']['station_id']] = feature\n",
    "\n",
    "        \n",
    "# Dictionary edge_id to edge_id\n",
    "# It used to know the neighboring edges of any edges present \n",
    "# in the geojson, we allow for 2 meters of imprecision       \n",
    "\n",
    "max_d = 5\n",
    "edgeid2edgeid = {}\n",
    "\n",
    "for edge_id1, feature1 in tqdm(edgeid2feature.items()):\n",
    "    edge_start_lat1 = feature1['geometry']['coordinates'][0][1]\n",
    "    edge_start_lng1 = feature1['geometry']['coordinates'][0][0]\n",
    "    edge_end_lat1 = feature1['geometry']['coordinates'][-1][1]\n",
    "    edge_end_lng1 = feature1['geometry']['coordinates'][-1][0]\n",
    "    \n",
    "    edges = []\n",
    "    \n",
    "    for edge_id2, feature2 in edgeid2feature.items():\n",
    "        if edge_id2 != edge_id1:\n",
    "            edge_start_lat2 = feature2['geometry']['coordinates'][0][1]\n",
    "            edge_start_lng2 = feature2['geometry']['coordinates'][0][0]\n",
    "            edge_end_lat2 = feature2['geometry']['coordinates'][-1][1]\n",
    "            edge_end_lng2 = feature2['geometry']['coordinates'][-1][0]\n",
    "\n",
    "            d1 = compute_distance(edge_start_lat1, edge_start_lng1, edge_start_lat2, edge_start_lng2)\n",
    "            d2 = compute_distance(edge_start_lat1, edge_start_lng1, edge_end_lat2, edge_end_lng2) \n",
    "            d3 = compute_distance(edge_end_lat1, edge_end_lng1, edge_start_lat2, edge_start_lng2)\n",
    "            d4 = compute_distance(edge_end_lat1, edge_end_lng1, edge_end_lat2, edge_end_lng2) \n",
    "\n",
    "            if d1 < max_d or d2 < max_d or d3 < max_d or d4 < max_d: \n",
    "                if (min(d1,d2,d3,d4) > 0.5):\n",
    "                    print(edge_id1, min(d1,d2,d3,d4))\n",
    "                edges.append(edge_id2)\n",
    "                \n",
    "    if not edges:\n",
    "         print(edge_id1)\n",
    "    \n",
    "    edgeid2edgeid[edge_id1] = edges    \n",
    "    \n",
    "# Dictionary stop_id to edge_id and its reverse\n",
    "# It is used to know the neighboring edges of any station present in geojson\n",
    "\n",
    "stopid2edgeid = {}\n",
    "for stop_id, feature in tqdm(stopid2coord.items()):\n",
    "    stop_lat = feature['geometry']['coordinates'][1]\n",
    "    stop_lng = feature['geometry']['coordinates'][0]\n",
    "    \n",
    "    edges = []\n",
    "    \n",
    "    for edge_id, feature in edgeid2feature.items():\n",
    "        edge_start_lat = feature['geometry']['coordinates'][0][1]\n",
    "        edge_start_lng = feature['geometry']['coordinates'][0][0]\n",
    "        edge_end_lat = feature['geometry']['coordinates'][-1][1]\n",
    "        edge_end_lng = feature['geometry']['coordinates'][-1][0]\n",
    "        \n",
    "        d_start = compute_distance(stop_lat, stop_lng, edge_start_lat, edge_start_lng)\n",
    "        d_end = compute_distance(stop_lat, stop_lng, edge_end_lat, edge_end_lng)\n",
    "        if d_start < max_d or d_end < max_d: \n",
    "            if (min(d_start,d_end) > 0.5):\n",
    "                    print(edge_id1, min(d_start,d_end))\n",
    "            edges.append(edge_id)\n",
    "            \n",
    "    if not edges:\n",
    "        print(\"Error\", stop_id)\n",
    "    \n",
    "    stopid2edgeid[stop_id] =  edges\n",
    "\n",
    "edgeid2stopid = {}\n",
    "for stopid, edgeids in tqdm(stopid2edgeid.items()):\n",
    "    for edgeid in edgeids:\n",
    "        if edgeid in edgeid2stopid:\n",
    "            edgeid2stopid[edgeid].append(stopid)\n",
    "        else:\n",
    "            edgeid2stopid[edgeid] = [stopid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = ['2017-01-30','2017-01-31','2017-02-01','2017-02-02','2017-02-03','2017-02-04','2017-02-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(out_dir + date + '_processed.csv', index_col=0)  for date in dates])\n",
    "df.columns = columns\n",
    "grouped = df.groupby(['trip_id', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = set()\n",
    "\n",
    "for name, group in tqdm(grouped, desc=\"Trips\"):\n",
    "    trip = group.sort_values(['stop_time_stop_sequence'])\n",
    "    \n",
    "    rows = trip.iterrows()\n",
    "    last_index, last_stop = next(rows)\n",
    "    \n",
    "    for next_index, next_stop in rows:\n",
    "        stop_1 = str(last_stop.stop_stop_id)\n",
    "        stop_2 = str(next_stop.stop_stop_id)\n",
    "        \n",
    "        if (stop_1, stop_2) not in keys and (stop_2, stop_1) not in keys:\n",
    "            keys.add((stop_1, stop_2))\n",
    "    \n",
    "        last_index, last_stop = (next_index, next_stop)\n",
    "    \n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all paires of stations and their path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trips_by_station_id = {}\n",
    "\n",
    "for key in tqdm(keys):\n",
    "    stop_1 = key[0] \n",
    "    stop_2 = key[1]\n",
    "        \n",
    "    if key not in trips_by_station_id and stop_1 in stopid2edgeid and stop_2 in stopid2edgeid:\n",
    "        start = sorted(stopid2edgeid[stop_1])\n",
    "        end = sorted(stopid2edgeid[stop_2])\n",
    "\n",
    "        for s in start:\n",
    "            for e in end:\n",
    "                r = bfs(edgeid2edgeid, s, e)\n",
    "                if key not in trips_by_station_id or len(trips_by_station_id[key]) > len(r):\n",
    "                    trips_by_station_id[key] = r           \n",
    "    else:\n",
    "        print(stop_1, stop_2)\n",
    "\n",
    "pickle.dump(trips_by_station_id, file=open(out_dir + \"trips_by_station_id.dump\", 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = {}\n",
    "for name, group in tqdm(grouped.get_group(grouped.get_ke), desc=\"Trips\"):\n",
    "    trip = group.sort_values(['stop_time_stop_sequence'])\n",
    "    \n",
    "    rows = trip.iterrows()\n",
    "    last_index, last_stop = next(rows)\n",
    "    \n",
    "    for next_index, next_stop in rows:\n",
    "        stop_1 = str(last_stop.stop_stop_id)\n",
    "        stop_2 = str(next_stop.stop_stop_id)\n",
    "        \n",
    "        key1 = (stop_1, stop_2)\n",
    "        key2 = (stop_2, stop_1)\n",
    "        \n",
    "        key_full = (name, last_stop.stop_id)\n",
    "        \n",
    "        path = None   \n",
    "        if key1 in trips_by_station_id:\n",
    "            path = trips_by_station_id[key1]\n",
    "        elif key2 in trips_by_station_id:\n",
    "            path = trips_by_station_id[key2].reverse()\n",
    "        \n",
    "        if (key_full not in paths) or (path and len(paths[key_full]) > len(path)):\n",
    "            paths[key_full] = path\n",
    "    \n",
    "        last_index, last_stop = (next_index, next_stop)\n",
    "        \n",
    "pickle.dump(paths, file=open(out_dir + \"paths.dump\", 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "064d13f138094e49bc67551fdb06bee2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "1df0c3acb6b24f3ebee5e55ccee37d83": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "3e806eae9c3843979d6bfbf14f711d0c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "62e3218607e24ba18c183a1a8b7d07fb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "71669e97c31e4e8fa25011c45186fe05": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "7a6c63fd8a6d44568e7845205336b676": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "8a5d67e19a4c4a97b703ec3c7667ea58": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "aac9a55d09f44d4c8669c860f449f2d7": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d62f76df93f34d6293200672f0bd1ead": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
